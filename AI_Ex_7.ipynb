{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeerthikaNagarajan/Ex-7-AAI/blob/main/AI_Ex_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8U3HvaJUz0W",
        "outputId": "40d3174d-7e30-479d-954f-f7ac49a64c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Natural language processing (NLP) is a subfield of artificial intelligence.\n",
            "It involves the development of algorithms and models that enact NLP.\n",
            "NLP is used in various applications, including chatbots, language Understanding, and language generation.\n",
            "This program demonstrates a simple text summarization using NLP\n",
            "\n",
            "Summary:\n",
            "NLP is used in various applications, including chatbots, language Understanding, and language generation. Natural language processing (NLP) is a subfield of artificial intelligence. It involves the development of algorithms and models that enact NLP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "    # Remove stopwords and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "    return stemmed_words\n",
        "\n",
        "def generate_summary(text, num_sentences=3):\n",
        "    sentences = sent_tokenize(text)\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "    # Calculate the frequency of each word\n",
        "    word_frequencies = nltk.FreqDist(preprocessed_text)\n",
        "\n",
        "    # Calculate the score for each sentence based on word frequency\n",
        "    sentence_scores = {}\n",
        "    for sentence in sentences:\n",
        "        for word, freq in word_frequencies.items():\n",
        "            if word in sentence.lower():\n",
        "                if sentence not in sentence_scores:\n",
        "                    sentence_scores[sentence] = freq\n",
        "                else:\n",
        "                    sentence_scores[sentence] += freq\n",
        "    # Select top N sentences with highest scores\n",
        "    summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
        "\n",
        "    return ' '.join(summary_sentences)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Read input from a file\n",
        "    file_path = \"input_text.txt\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        input_text = file.read()\n",
        "\n",
        "    summary = generate_summary(input_text)\n",
        "    print(\"Original Text:\")\n",
        "    print(input_text)\n",
        "    print(\"\\nSummary:\")\n",
        "    print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E99cNN73U3C1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}